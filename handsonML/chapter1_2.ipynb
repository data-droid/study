{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 머신러닝의 주요 도전과제\n",
    "학습과정에서 발생할 수 있는 문제와 예측을 방해하는 요인들."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 충분하지 않은 양의 훈련 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1yEC37hULEyX3g2n3xLr3Pk72VpRlmPW8\" width=\"400\">\n",
    "<div class=\"caption\" style='text-align:center'>1-20</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위는 자연어 중의성 해소문제 알고리즘을 나타내며, 모두 데이터양이 많아질 수록 거의 비슷하게 잘 처리함을 보임.<br>\n",
    "즉, 알고리즘보다 데이터가 더 중요함.(데이터셋이 적다면 알고리즘도 무시할 수는 없음.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 대표성 없는 훈련 데이터\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1YcWvppfxIqxhJQQvLQ2iIEe3wYpD0RgA\" width=\"400\">\n",
    "<div class=\"caption\" style='text-align:center'>1-21</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반화가 잘되기 위해 Training Set이 대표성이 필요함. 위 그림에서 기존 데이터와 달리 빨간색 점들의 데이터가 추가되었을 경우 새로운 모델을 얻게됨. 해당 데이터들을 만족하기에 선형 모델로는 한계가 있어 보임.\n",
    "따라서, 일반화하려는 사례를 대표하는 훈련 세트를 사용하는 것이 중요하나 어려움이 많음.\n",
    "* 샘플링 잡음 (sampling noise) : 샘플이 작을때 대표성 없는 데이터가 생김.\n",
    "* 샘플링 편향 (sampling bias) : 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못함.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3 낮은 품질의 데이터\n",
    "데이터가 error, outlier, noise 가 있다면 패턴을 찾기 어렵기 때문에 무시하거나 따로 훈련시키거나 평균으로 수정하는 등의 방법이 필요함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.4 관련 없는 특성\n",
    "Garbage in Garbage out!좋은 특성을 찾아야하며 이를 feature engineering 이라고 함.\n",
    "* 특성 선택 (feature selection) : 가장 유용한 특성 선택\n",
    "* 특성 추출 (feature extraction) : 특성을 결합하여 더 유용한 특성 생성\n",
    "* 새로운 데이터 수집을 통한 새 특성 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.5 훈련 데이터 과대 적합\n",
    "* 과대적합 (overfitting) : 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어지는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1d06MxG7PNP4IEUBL61KwT8J7wgxc1mvp\" width=\"400\">\n",
    "<div class=\"caption\" style='text-align:center'>1-22</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 고차원 다항 회귀 모델이 과대적합의 경우이다. 훈련 데이터에 잘 맞더라도 실제 예측을 믿기는 힘듬.\n",
    "\n",
    "과대적합은 잡음의 양에 비해 모델이 너무 복잡할때 발생. \n",
    "* 파라미터 수가 적은 모델 선택, 특성 수를 줄임, 모델에 제약을 줘 단순화 함\n",
    "* 더 많은 데이터 수집\n",
    "* noise 제거\n",
    "\n",
    "자유도 (degree of freedom)\n",
    "> 선형 모델의 경우 기울기와 y절편 값을 조절하게됨. \n",
    "> - 기울기를 0으로 강제시 y절편 자유도만 남아 일반화는 되나, 데이터에 맞추기 어려움.\n",
    "> - 기울기를 작은 값을 갖도록 유지하면 자유도 1과 2사이의 적절하게 위치함.\n",
    "\n",
    ">데이터를 맞추는 것과 일반화를 위해 단순한 모델을 유지하는 것 사이의 균형이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=13LaovF_zZ9Xc2pOoWwn55DPW27OgxNea\" width=\"400\">\n",
    "<div class=\"caption\" style='text-align:center'>1-23</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파란색이 Training Set일 때, 전체데이터와 부분데이터를 사용한 것보다 Regularize(규제)하여 모델에 제약을 준 것이 빨간색 새로 들어온 데이터에 더 잘 일반화 됨을 보임\n",
    "\n",
    "하이퍼파라미터 (hyperparameter) : 학습시 적용할 규제의 양\n",
    "* 학습 알고리즘으로부터 영향을 받지 않음\n",
    "* 학습 전 미리 지정하며 학습 동안 상수로 사용됨.\n",
    "* 클 수록 기울기가 0에 가까워지며 과대적합될 가능성은 낮아지나 좋은 모델을 찾지 못할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.6 훈련 데이터 과소적합\n",
    "모델이 너무 단순해서 학습을 못할 때. (과대적합의 반대)\n",
    "* 파라미터가 더 많은 강력한 모델 선택\n",
    "* 더 좋은 특성을 사용\n",
    "* 모델의 제약을 줄임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.7 한걸음 물러서서 (summary)\n",
    "* 머신러닝 : 명시적 규칙을 코딩하지 않고 데이터로부터 학습하는 것\n",
    "* 종류 : 지도/비지도 학습, 배치/온라인 학습, 사례기반/모델기반 학습\n",
    "    * 모델기반 : 훈련 세트에 모델을 맞추기 위해 파라미터 조정하여 새로운 데이터에도 좋은 예측이 되도록 함.\n",
    "    * 사례기반 : 샘플을 기억하는 것이 학습이고 새로운 샘플에 일반화하기 위해 유사도 측정을 사용하는 것\n",
    "* garbage in garbage out : 훈련 세트가 중요함\n",
    "* 모델은 너무 단순(underfitting)해서도 너무 복잡(overfitting)해서도 안됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 테스트와 검증\n",
    "모델을 테스트하기위해 훈련세트를 훈련세트(80%)와 테스트세트(20%)로 나눔.\n",
    "* 훈련 세트 : 모델을 훈련\n",
    "* 테스트 세트 : 모델을 테스트\n",
    "* 일반화 오차 (generalization error) : 새로운 샘플에 대한 오류 비율 (= 외부 샘플 오차 out-of-sample error)\n",
    "* 훈련 오차는 낮지만 일반화 오차가 높으면 overfitting 되었음을 말함\n",
    "\n",
    "테스트 세트를 이용하게 되면, 반복시 모델과 하이퍼파라미터가 테스트 세트에 최적화 될 수 있음.\n",
    "* 검증 세트 (validation set)를 만들어 다양한 하이퍼파라미터로 만들어진 여러 모델 중 최상의 성능을 내는 모델과 하이퍼파라미터를 찾음\n",
    "    * 위 과정에서 만족스러운 모델을 찾으면 테스트 세트로 일반화 오차의 추정값을 얻기 위해 최종 테스트 진행.\n",
    "* 교차 검증 (cross-validation) : 훈련 세트를 여러 서브셋으로 나눠 각 모델을 이 서브셋의 조합으로 훈련시키고 남은 부분으로 검증.\n",
    "    * 모델과 하이퍼파라미터가 선택되면 전체 훈련 세트로 최종 모델을 훈련시키고 테스트 세트로 일반화 오차 측정.\n",
    "    \n",
    "#### 공짜 점심 없음 이론\n",
    "최선의 모델은 모든 모델 평가를 해보는 것 뿐이지만, 불가능하기 때문에 타당한 가정을 하고 적절한 모델 몇 가지만 평가.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
